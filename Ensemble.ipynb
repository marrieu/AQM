{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/mariavarga/AQM/AQM_SessionMaterial/Weekly_Material/Week_6/hgsc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABHD2</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>ACTR2</th>\n",
       "      <th>ACTR5</th>\n",
       "      <th>ACVR2A</th>\n",
       "      <th>ADAMDEC1</th>\n",
       "      <th>ADCYAP1R1</th>\n",
       "      <th>AEBP1</th>\n",
       "      <th>...</th>\n",
       "      <th>WT1</th>\n",
       "      <th>XPO7</th>\n",
       "      <th>XPOT</th>\n",
       "      <th>YTHDC2</th>\n",
       "      <th>ZDHHC14</th>\n",
       "      <th>ZDHHC7</th>\n",
       "      <th>ZEB1</th>\n",
       "      <th>ZFP36</th>\n",
       "      <th>ZHX3</th>\n",
       "      <th>ZNF423</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRO.C5</td>\n",
       "      <td>-0.010674</td>\n",
       "      <td>0.263376</td>\n",
       "      <td>-0.115492</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>-0.504271</td>\n",
       "      <td>-1.283720</td>\n",
       "      <td>-0.433908</td>\n",
       "      <td>0.673072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077048</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>-0.072049</td>\n",
       "      <td>0.243935</td>\n",
       "      <td>-0.056318</td>\n",
       "      <td>-0.204971</td>\n",
       "      <td>0.179639</td>\n",
       "      <td>-0.292136</td>\n",
       "      <td>-0.034261</td>\n",
       "      <td>0.490152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-0.710741</td>\n",
       "      <td>0.110421</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>-0.253877</td>\n",
       "      <td>-0.389024</td>\n",
       "      <td>-0.121941</td>\n",
       "      <td>-1.732920</td>\n",
       "      <td>-0.727880</td>\n",
       "      <td>1.706110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547120</td>\n",
       "      <td>-0.674773</td>\n",
       "      <td>-0.236746</td>\n",
       "      <td>0.551354</td>\n",
       "      <td>0.215982</td>\n",
       "      <td>0.196677</td>\n",
       "      <td>1.467320</td>\n",
       "      <td>2.461040</td>\n",
       "      <td>0.415041</td>\n",
       "      <td>2.116880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIF.C4</td>\n",
       "      <td>0.881506</td>\n",
       "      <td>0.372862</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>-0.848119</td>\n",
       "      <td>-1.281180</td>\n",
       "      <td>1.524370</td>\n",
       "      <td>-0.288317</td>\n",
       "      <td>-2.010830</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058170</td>\n",
       "      <td>0.350895</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.592285</td>\n",
       "      <td>-0.338954</td>\n",
       "      <td>-0.842242</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>-0.471005</td>\n",
       "      <td>-1.662190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-1.085090</td>\n",
       "      <td>0.415651</td>\n",
       "      <td>0.395376</td>\n",
       "      <td>-0.271050</td>\n",
       "      <td>0.146536</td>\n",
       "      <td>-0.363270</td>\n",
       "      <td>0.993823</td>\n",
       "      <td>-0.450427</td>\n",
       "      <td>1.999170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677226</td>\n",
       "      <td>-0.109778</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.760080</td>\n",
       "      <td>-1.169030</td>\n",
       "      <td>0.325604</td>\n",
       "      <td>1.785760</td>\n",
       "      <td>-0.212328</td>\n",
       "      <td>0.537493</td>\n",
       "      <td>-0.102138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-0.932230</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>0.595068</td>\n",
       "      <td>0.187856</td>\n",
       "      <td>-0.200287</td>\n",
       "      <td>0.211144</td>\n",
       "      <td>1.844640</td>\n",
       "      <td>-0.416482</td>\n",
       "      <td>1.327800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>0.529045</td>\n",
       "      <td>-0.551470</td>\n",
       "      <td>-0.188697</td>\n",
       "      <td>0.157393</td>\n",
       "      <td>0.469166</td>\n",
       "      <td>1.748000</td>\n",
       "      <td>0.144196</td>\n",
       "      <td>-0.561641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class      ABAT     ABHD2      ACTB     ACTR2     ACTR5    ACVR2A  \\\n",
       "0  PRO.C5 -0.010674  0.263376 -0.115492 -0.323565  0.005161 -0.504271   \n",
       "1  MES.C1 -0.710741  0.110421  0.532555 -0.253877 -0.389024 -0.121941   \n",
       "2  DIF.C4  0.881506  0.372862  0.052344  0.028721 -0.848119 -1.281180   \n",
       "3  MES.C1 -1.085090  0.415651  0.395376 -0.271050  0.146536 -0.363270   \n",
       "4  MES.C1 -0.932230  0.045352  0.595068  0.187856 -0.200287  0.211144   \n",
       "\n",
       "   ADAMDEC1  ADCYAP1R1     AEBP1    ...          WT1      XPO7      XPOT  \\\n",
       "0 -1.283720  -0.433908  0.673072    ...     0.077048  0.459961 -0.072049   \n",
       "1 -1.732920  -0.727880  1.706110    ...     0.547120 -0.674773 -0.236746   \n",
       "2  1.524370  -0.288317 -2.010830    ...     1.058170  0.350895 -0.000051   \n",
       "3  0.993823  -0.450427  1.999170    ...    -0.677226 -0.109778  0.033163   \n",
       "4  1.844640  -0.416482  1.327800    ...     0.961688 -0.009010  0.529045   \n",
       "\n",
       "     YTHDC2   ZDHHC14    ZDHHC7      ZEB1     ZFP36      ZHX3    ZNF423  \n",
       "0  0.243935 -0.056318 -0.204971  0.179639 -0.292136 -0.034261  0.490152  \n",
       "1  0.551354  0.215982  0.196677  1.467320  2.461040  0.415041  2.116880  \n",
       "2  0.010498  0.592285 -0.338954 -0.842242  0.096242 -0.471005 -1.662190  \n",
       "3  0.760080 -1.169030  0.325604  1.785760 -0.212328  0.537493 -0.102138  \n",
       "4 -0.551470 -0.188697  0.157393  0.469166  1.748000  0.144196 -0.561641  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABHD2</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>ACTR2</th>\n",
       "      <th>ACTR5</th>\n",
       "      <th>ACVR2A</th>\n",
       "      <th>ADAMDEC1</th>\n",
       "      <th>ADCYAP1R1</th>\n",
       "      <th>AEBP1</th>\n",
       "      <th>AFP</th>\n",
       "      <th>...</th>\n",
       "      <th>WT1</th>\n",
       "      <th>XPO7</th>\n",
       "      <th>XPOT</th>\n",
       "      <th>YTHDC2</th>\n",
       "      <th>ZDHHC14</th>\n",
       "      <th>ZDHHC7</th>\n",
       "      <th>ZEB1</th>\n",
       "      <th>ZFP36</th>\n",
       "      <th>ZHX3</th>\n",
       "      <th>ZNF423</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>489.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008387</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>-0.048004</td>\n",
       "      <td>0.046372</td>\n",
       "      <td>-0.002119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.027301</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>-0.017932</td>\n",
       "      <td>-0.020583</td>\n",
       "      <td>-0.008142</td>\n",
       "      <td>-0.001834</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>-0.021180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.855034</td>\n",
       "      <td>0.336518</td>\n",
       "      <td>0.397348</td>\n",
       "      <td>0.488962</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.585289</td>\n",
       "      <td>1.717745</td>\n",
       "      <td>0.828748</td>\n",
       "      <td>1.127358</td>\n",
       "      <td>0.282604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070487</td>\n",
       "      <td>0.529161</td>\n",
       "      <td>0.565231</td>\n",
       "      <td>0.470871</td>\n",
       "      <td>0.536496</td>\n",
       "      <td>0.434298</td>\n",
       "      <td>0.695861</td>\n",
       "      <td>1.073584</td>\n",
       "      <td>0.363393</td>\n",
       "      <td>1.039991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.554020</td>\n",
       "      <td>-1.003640</td>\n",
       "      <td>-2.140110</td>\n",
       "      <td>-1.673060</td>\n",
       "      <td>-1.049950</td>\n",
       "      <td>-1.815440</td>\n",
       "      <td>-2.460760</td>\n",
       "      <td>-1.880380</td>\n",
       "      <td>-2.327670</td>\n",
       "      <td>-0.528737</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.666230</td>\n",
       "      <td>-1.555500</td>\n",
       "      <td>-1.926060</td>\n",
       "      <td>-1.365750</td>\n",
       "      <td>-1.324680</td>\n",
       "      <td>-1.416760</td>\n",
       "      <td>-1.252370</td>\n",
       "      <td>-2.983640</td>\n",
       "      <td>-0.885721</td>\n",
       "      <td>-2.115570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.587382</td>\n",
       "      <td>-0.250230</td>\n",
       "      <td>-0.217561</td>\n",
       "      <td>-0.271547</td>\n",
       "      <td>-0.266923</td>\n",
       "      <td>-0.394082</td>\n",
       "      <td>-1.401060</td>\n",
       "      <td>-0.578924</td>\n",
       "      <td>-0.877261</td>\n",
       "      <td>-0.168286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273779</td>\n",
       "      <td>-0.369139</td>\n",
       "      <td>-0.338244</td>\n",
       "      <td>-0.340431</td>\n",
       "      <td>-0.372141</td>\n",
       "      <td>-0.309520</td>\n",
       "      <td>-0.510041</td>\n",
       "      <td>-0.717118</td>\n",
       "      <td>-0.258826</td>\n",
       "      <td>-0.809547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.094442</td>\n",
       "      <td>-0.028207</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>0.036482</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>-0.010645</td>\n",
       "      <td>-0.436778</td>\n",
       "      <td>-0.273248</td>\n",
       "      <td>-0.104342</td>\n",
       "      <td>-0.032026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222207</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.034492</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>-0.059939</td>\n",
       "      <td>-0.023154</td>\n",
       "      <td>-0.144509</td>\n",
       "      <td>-0.136597</td>\n",
       "      <td>-0.034390</td>\n",
       "      <td>-0.217582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.494171</td>\n",
       "      <td>0.197399</td>\n",
       "      <td>0.259491</td>\n",
       "      <td>0.361896</td>\n",
       "      <td>0.257652</td>\n",
       "      <td>0.399105</td>\n",
       "      <td>1.201670</td>\n",
       "      <td>0.234490</td>\n",
       "      <td>0.900145</td>\n",
       "      <td>0.133220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684458</td>\n",
       "      <td>0.383051</td>\n",
       "      <td>0.377870</td>\n",
       "      <td>0.336609</td>\n",
       "      <td>0.278740</td>\n",
       "      <td>0.256288</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.690172</td>\n",
       "      <td>0.228475</td>\n",
       "      <td>0.680371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.427710</td>\n",
       "      <td>1.068670</td>\n",
       "      <td>1.475420</td>\n",
       "      <td>1.209200</td>\n",
       "      <td>1.734370</td>\n",
       "      <td>2.329080</td>\n",
       "      <td>6.137360</td>\n",
       "      <td>4.650470</td>\n",
       "      <td>2.767840</td>\n",
       "      <td>3.724850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.927930</td>\n",
       "      <td>1.326440</td>\n",
       "      <td>2.387230</td>\n",
       "      <td>1.582340</td>\n",
       "      <td>2.251250</td>\n",
       "      <td>1.413860</td>\n",
       "      <td>2.885200</td>\n",
       "      <td>3.571340</td>\n",
       "      <td>1.624300</td>\n",
       "      <td>3.741350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ABAT       ABHD2        ACTB       ACTR2       ACTR5      ACVR2A  \\\n",
       "count  489.000000  489.000000  489.000000  489.000000  489.000000  489.000000   \n",
       "mean     0.008387   -0.018389    0.006567    0.026521    0.010781    0.008681   \n",
       "std      0.855034    0.336518    0.397348    0.488962    0.415855    0.585289   \n",
       "min     -1.554020   -1.003640   -2.140110   -1.673060   -1.049950   -1.815440   \n",
       "25%     -0.587382   -0.250230   -0.217561   -0.271547   -0.266923   -0.394082   \n",
       "50%     -0.094442   -0.028207    0.019348    0.036482   -0.010406   -0.010645   \n",
       "75%      0.494171    0.197399    0.259491    0.361896    0.257652    0.399105   \n",
       "max      3.427710    1.068670    1.475420    1.209200    1.734370    2.329080   \n",
       "\n",
       "         ADAMDEC1   ADCYAP1R1       AEBP1         AFP     ...             WT1  \\\n",
       "count  489.000000  489.000000  489.000000  489.000000     ...      489.000000   \n",
       "mean     0.034882   -0.048004    0.046372   -0.002119     ...        0.053700   \n",
       "std      1.717745    0.828748    1.127358    0.282604     ...        1.070487   \n",
       "min     -2.460760   -1.880380   -2.327670   -0.528737     ...       -6.666230   \n",
       "25%     -1.401060   -0.578924   -0.877261   -0.168286     ...       -0.273779   \n",
       "50%     -0.436778   -0.273248   -0.104342   -0.032026     ...        0.222207   \n",
       "75%      1.201670    0.234490    0.900145    0.133220     ...        0.684458   \n",
       "max      6.137360    4.650470    2.767840    3.724850     ...        1.927930   \n",
       "\n",
       "             XPO7        XPOT      YTHDC2     ZDHHC14      ZDHHC7        ZEB1  \\\n",
       "count  489.000000  489.000000  489.000000  489.000000  489.000000  489.000000   \n",
       "mean     0.009031    0.027301    0.004048   -0.017932   -0.020583   -0.008142   \n",
       "std      0.529161    0.565231    0.470871    0.536496    0.434298    0.695861   \n",
       "min     -1.555500   -1.926060   -1.365750   -1.324680   -1.416760   -1.252370   \n",
       "25%     -0.369139   -0.338244   -0.340431   -0.372141   -0.309520   -0.510041   \n",
       "50%      0.000197    0.034492   -0.003826   -0.059939   -0.023154   -0.144509   \n",
       "75%      0.383051    0.377870    0.336609    0.278740    0.256288    0.383663   \n",
       "max      1.326440    2.387230    1.582340    2.251250    1.413860    2.885200   \n",
       "\n",
       "            ZFP36        ZHX3      ZNF423  \n",
       "count  489.000000  489.000000  489.000000  \n",
       "mean    -0.001834    0.001288   -0.021180  \n",
       "std      1.073584    0.363393    1.039991  \n",
       "min     -2.983640   -0.885721   -2.115570  \n",
       "25%     -0.717118   -0.258826   -0.809547  \n",
       "50%     -0.136597   -0.034390   -0.217582  \n",
       "75%      0.690172    0.228475    0.680371  \n",
       "max      3.571340    1.624300    3.741350  \n",
       "\n",
       "[8 rows x 321 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['class'],axis =1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DIF.C4', 'IMM.C2', 'MES.C1', 'PRO.C5'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def score_to_numeric(x):\n",
    "  #  if x=='DIF.C4':\n",
    "   #     return 1\n",
    "    #if x=='IMM.C2':\n",
    "      #  return 2\n",
    "    #if x=='MES.C1':\n",
    "     #   return 3\n",
    "    #if x=='PRO.C5':\n",
    "       # return 4\n",
    "#y=y.apply(score_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "# apply encoding to labels\n",
    "labels = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 135.,    0.,    0.,  107.,    0.,    0.,  109.,    0.,    0.,  138.]),\n",
       " array([ 0. ,  0.3,  0.6,  0.9,  1.2,  1.5,  1.8,  2.1,  2.4,  2.7,  3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109392a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM = svm.SVC(kernel='linear', C=0.1)\n",
    "model_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_SVM = model_SVM.predict(X_train)\n",
    "pred_test_SVM = model_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8950617283950617\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_SVM)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_SVM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  3  2  1]\n",
      " [ 2 30  2  0]\n",
      " [ 1  0 30  2]\n",
      " [ 3  1  0 43]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "model_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_RF = model_RF.predict(X_train)\n",
    "pred_test_RF = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8746177370030581\n",
      "Test accuracy: 0.7962962962962963\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_RF)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  3  0 12]\n",
      " [ 4 28  2  0]\n",
      " [ 0  5 30  1]\n",
      " [ 4  0  2 43]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LD = LinearDiscriminantAnalysis()\n",
    "model_LD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_LD = model_LD.predict(X_train)\n",
    "pred_test_LD = model_LD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.3271604938271605\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_LD)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_LD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12 12 12]\n",
      " [ 6 13  9 13]\n",
      " [ 6  5 13 11]\n",
      " [ 4  8 11 22]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_LD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_QD = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariavarga/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_QD = QuadraticDiscriminantAnalysis()\n",
    "model_QD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_QD = model_QD.predict(X_train)\n",
    "pred_test_QD = model_QD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.32098765432098764\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_QD)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_QD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 14 12  2]\n",
      " [ 8  9 13 10]\n",
      " [ 6  9 14  6]\n",
      " [ 6 11 13 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_QD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('SVM', model_SVM), ('RF', model_RF), ('LD', model_LD), ('QD', model_QD)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariavarga/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SVM', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)), ('RF', RandomForestClassifier(bootstrap=True, clas...rs=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = eclf1.predict(X_train)\n",
    "pred_test = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7839506172839507\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  1  4]\n",
      " [12 25  2  2]\n",
      " [ 1  0 34  1]\n",
      " [ 8  1  3 31]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_model(model,X):\n",
    "    \n",
    "    X_model = model.predict(X)\n",
    "    \n",
    "    return X_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_SVM = apply_model(model_SVM,X)\n",
    "X_RF = apply_model(model_RF,X)\n",
    "X_LD = apply_model(model_LD,X)\n",
    "X_QD = apply_model(model_QD,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ens = np.transpose(np.vstack((X_SVM,X_RF,X_LD,X_QD)))\n",
    "#X_ens = pd.DataFrame({\"X_SVM\":X_SVM,\"X_RF\":X_RF,\"X_LD\":X_LD,\"X_QD\":X_QD})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ens_train, X_ens_test, y_train, y_test = train_test_split(X_ens, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stk = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk.fit(X_ens_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_stk = stk.predict(X_ens_train)\n",
    "pred_test_stk = stk.predict(X_ens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.944954128440367\n",
      "Test accuracy: 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_stk)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_stk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  9 13 10]\n",
      " [13  5 13  3]\n",
      " [14  3  7  9]\n",
      " [15  9  7 16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking NN (because why not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.core import Activation,Dropout,Dense, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to one hot encoding\n",
    "dummy_y = np_utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ens, dummy_y, test_size=0.33, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape=4):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    X = BatchNormalization()(inputs)\n",
    "    X = Dense(4,activation='softmax')(inputs)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = get_model(input_shape=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01)\n",
    "NN.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "327/327 [==============================] - 0s - loss: 0.3891 - acc: 0.9419 - val_loss: 0.5670 - val_acc: 0.8951\n",
      "Epoch 2/10\n",
      "327/327 [==============================] - 0s - loss: 0.3908 - acc: 0.9450 - val_loss: 0.5669 - val_acc: 0.8951\n",
      "Epoch 3/10\n",
      "327/327 [==============================] - 0s - loss: 0.3874 - acc: 0.9480 - val_loss: 0.5643 - val_acc: 0.8827\n",
      "Epoch 4/10\n",
      "327/327 [==============================] - 0s - loss: 0.3850 - acc: 0.9419 - val_loss: 0.5641 - val_acc: 0.8951\n",
      "Epoch 5/10\n",
      "327/327 [==============================] - 0s - loss: 0.3835 - acc: 0.9450 - val_loss: 0.5643 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "327/327 [==============================] - 0s - loss: 0.3849 - acc: 0.9450 - val_loss: 0.5619 - val_acc: 0.9012\n",
      "Epoch 7/10\n",
      "327/327 [==============================] - 0s - loss: 0.3802 - acc: 0.9511 - val_loss: 0.5612 - val_acc: 0.9012\n",
      "Epoch 8/10\n",
      "327/327 [==============================] - 0s - loss: 0.3800 - acc: 0.9480 - val_loss: 0.5601 - val_acc: 0.9012\n",
      "Epoch 9/10\n",
      "327/327 [==============================] - 0s - loss: 0.3772 - acc: 0.9511 - val_loss: 0.5590 - val_acc: 0.9012\n",
      "Epoch 10/10\n",
      "327/327 [==============================] - 0s - loss: 0.3764 - acc: 0.9480 - val_loss: 0.5577 - val_acc: 0.9012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24dbab38>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(X_train, y_train, epochs=10, validation_data = (X_test, y_test),shuffle = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_np = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_np, dummy_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 321)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape=321):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    #X = BatchNormalization()(inputs)\n",
    "    X = Dropout(0.7)(inputs)\n",
    "    X = Dense(60,activation='relu')(X)\n",
    "    #X = Dense(60,activation='relu',activity_regularizer=l1(0.01))(X)\n",
    "    #X = Dropout(0.3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    #X = Dense(20,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(4,activation='softmax')(X)\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 321)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 321)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 60)                19320     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 244       \n",
      "=================================================================\n",
      "Total params: 19,804\n",
      "Trainable params: 19,684\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01)\n",
    "NN.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "327/327 [==============================] - 0s - loss: 0.3764 - acc: 0.8349 - val_loss: 0.3484 - val_acc: 0.8951\n",
      "Epoch 2/10\n",
      "327/327 [==============================] - 0s - loss: 0.3216 - acc: 0.8899 - val_loss: 0.3314 - val_acc: 0.9012\n",
      "Epoch 3/10\n",
      "327/327 [==============================] - 0s - loss: 0.4025 - acc: 0.8440 - val_loss: 0.3153 - val_acc: 0.9012\n",
      "Epoch 4/10\n",
      "327/327 [==============================] - 0s - loss: 0.3595 - acc: 0.8502 - val_loss: 0.3165 - val_acc: 0.9136\n",
      "Epoch 5/10\n",
      "327/327 [==============================] - 0s - loss: 0.3729 - acc: 0.8593 - val_loss: 0.3008 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      "327/327 [==============================] - 0s - loss: 0.3775 - acc: 0.8624 - val_loss: 0.2876 - val_acc: 0.9136\n",
      "Epoch 7/10\n",
      "327/327 [==============================] - 0s - loss: 0.3176 - acc: 0.8777 - val_loss: 0.2781 - val_acc: 0.9136\n",
      "Epoch 8/10\n",
      "327/327 [==============================] - 0s - loss: 0.3315 - acc: 0.8746 - val_loss: 0.2746 - val_acc: 0.9321\n",
      "Epoch 9/10\n",
      "327/327 [==============================] - 0s - loss: 0.2855 - acc: 0.8930 - val_loss: 0.2722 - val_acc: 0.9074\n",
      "Epoch 10/10\n",
      "327/327 [==============================] - 0s - loss: 0.3325 - acc: 0.8685 - val_loss: 0.2648 - val_acc: 0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c28886cf8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(X_train, y_train, epochs=10, validation_data = (X_test, y_test),shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_NN = NN.predict(X_train)\n",
    "pred_test_NN = NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9908256880733946\n",
      "Test accuracy: 0.9197530864197531\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(np.argmax(y_train,axis=1),np.argmax(pred_train_NN,axis=1))))\n",
    "print('Test accuracy: {}'.format(accuracy_score(np.argmax(y_test,axis=1),np.argmax(pred_test_NN,axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  3  3]\n",
      " [ 1 32  1  0]\n",
      " [ 1  0 32  0]\n",
      " [ 2  0  2 43]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_test,axis=1),np.argmax(pred_test_NN,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model2(input_shape=321):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    #X = BatchNormalization()(inputs)\n",
    "    X = Dropout(0.7)(inputs)\n",
    "    X = Dense(10,activation='relu')(X)\n",
    "    X = Dropout(0.7)(inputs)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(30,activation='relu')(X)\n",
    "    X = Dropout(0.7)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(10,activation='relu')(X)\n",
    "    X = Dropout(0.7)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(4,activation='softmax')(X)\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN2 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01)\n",
    "NN2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples, validate on 162 samples\n",
      "Epoch 1/5\n",
      "327/327 [==============================] - 0s - loss: 0.4267 - acc: 0.8471 - val_loss: 0.5391 - val_acc: 0.8704\n",
      "Epoch 2/5\n",
      "327/327 [==============================] - 0s - loss: 0.4483 - acc: 0.7982 - val_loss: 0.5042 - val_acc: 0.8889\n",
      "Epoch 3/5\n",
      "327/327 [==============================] - 0s - loss: 0.3592 - acc: 0.8654 - val_loss: 0.4562 - val_acc: 0.9136\n",
      "Epoch 4/5\n",
      "327/327 [==============================] - 0s - loss: 0.3866 - acc: 0.8349 - val_loss: 0.4152 - val_acc: 0.9136\n",
      "Epoch 5/5\n",
      "327/327 [==============================] - 0s - loss: 0.4291 - acc: 0.8440 - val_loss: 0.3928 - val_acc: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2b5f95f8>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN2.fit(X_train, y_train, epochs=5, validation_data = (X_test, y_test),shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_NN2 = NN2.predict(X_train)\n",
    "pred_test_NN2 = NN2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9877675840978594\n",
      "Test accuracy: 0.9135802469135802\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(np.argmax(y_train,axis=1),np.argmax(pred_train_NN2,axis=1))))\n",
    "print('Test accuracy: {}'.format(accuracy_score(np.argmax(y_test,axis=1),np.argmax(pred_test_NN2,axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
